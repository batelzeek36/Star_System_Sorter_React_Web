# Design Document

## Overview

The Quote Extraction System is a Python-based pipeline that processes OCR text from **Ra Uru Hu’s Line Companion**, cross-checks it against the **canonical I Ching hexagram files** in `s3-data/hexagrams/`, extracts quotes under 25 words for all **384 gate.lines**, and integrates them into the S³ JSON data files with proper citations.

The goal: **no drift** between Human Design gates ↔ I Ching hexagrams ↔ star-system mappings.

The system:

- picks the **best available Line Companion source** (djvu/epub → normalized),
- extracts gate → line text,
- picks a sub-25-word excerpt,
- **verifies it against the corresponding hexagram**,
- and only then writes a **candidate** gate file.

It also produces a **BAD_LINES.md** for anything that can’t be extracted cleanly.

---

## Source Priority (authoritative)

1. **Primary**: `lore-research/research-outputs/line-companion-normalized.txt`  
   (if present, this is the one to use — it was already cleaned)
2. **If missing/corrupt**: `s3-data/Line Companion_djvu.txt` or `s3-data/Line Companion.epub`
3. **Additional sources**: `s3-data/Line Companion_abbyy.gz`, `s3-data/Line Companion_djvu.xml`, `s3-data/Line Companion_scandata.xml`
4. **If the line is still missing or OCR-garbled**: fall back to the I Ching dump:
   - `s3-data/236066-The I Ching_djvu.txt`
   - line meaning must match the hexagram in `s3-data/hexagrams/<NN>.json`
5. **If both LC + I Ching fail** → mark as **provisional** and send to manual queue.

**Traceability**: Each stage logs `source_file` (and `source_offset` if known) for every extracted quote.

Old auto-generated files:
- `lore-research/research-outputs/line-companion-gate-lines.json`
- `lore-research/research-outputs/line-companion-gates.json`
- `lore-research/research-outputs/line-companion-quotes.json`
are **non-authoritative** and may be deleted or regenerated by this pipeline.

---

## Architecture

### Pipeline Stages

```

[1. Normalization] → [2. Gate Splitting] → [3. Line Extraction]
↓                      ↓                     ↓
(LC)                   (LC)                  (LC)
└──────────────→ [3b. Hexagram Cross-Check] ←──────────────┘
↓
[4. Quote Selection]
↓
[5. Integration & Validation]

````

Each stage writes an artifact so we can diff, re-run, or hand to another model.

---

## Data Flow

1. **Input candidates** (pick best):
   - `lore-research/research-outputs/line-companion-normalized.txt` (preferred)
   - else `s3-data/Line Companion_djvu.txt`
   - else `s3-data/Line Companion.epub`
   - else `s3-data/Line Companion_abbyy.gz`
   - else `s3-data/Line Companion_djvu.xml`
   - else `s3-data/Line Companion_scandata.xml`
2. **Stage 1 Output**: `lore-research/research-outputs/line-companion-normalized.txt`
3. **Stage 2 Output**: `lore-research/research-outputs/line-companion-gates.json`
4. **Stage 3 Output**: `lore-research/research-outputs/line-companion-gate-lines.json`
5. **Stage 3b Output (new)**: `lore-research/research-outputs/line-companion-gate-lines-xchecked.json`
   - same as Stage 3 but with `hexagram_match` / `hexagram_conflict` flags
6. **Stage 4 Output**: `lore-research/research-outputs/line-companion-quotes.json`
7. **Final Output (candidate)**: `s3-data/gates/_candidate/*.json` (64 files)
   - human/agent can later promote to `s3-data/gates/*.json`

---

## Components and Interfaces

### 1. Text Normalizer (`01-normalize-line-companion.py`)

**Purpose**: clean OCR so regex works.

**Input**: first existing of:
- `lore-research/research-outputs/line-companion-normalized.txt`
- `s3-data/Line Companion_djvu.txt`
- `s3-data/Line Companion.epub`
- `s3-data/Line Companion_abbyy.gz`
- `s3-data/Line Companion_djvu.xml`
- `s3-data/Line Companion_scandata.xml`

**Logic**:
- normalize line endings
- collapse 3+ blank lines → 1
- join mid-sentence newlines
- light OCR fixes (configurable dict)

**Output**:
- `lore-research/research-outputs/line-companion-normalized.txt`

**Notes**:
- if input was already normalized, just rewrite it (idempotent)
- log any line >1500 chars → possible OCR mess

---

### 2. Gate Splitter (`02-split-gates.py`)

**Purpose**: get 64 blocks.

**Input**:
- `lore-research/research-outputs/line-companion-normalized.txt`

**Logic**:
- regex for headings like: `^(Gate|HEXAGRAM)\s+(\d{1,2})[^\n]*\n`
- capture text until next heading or EOF
- expected: 64

**Output**:
```json
{
  "1": { "title": "Gate 1 – The Creative", "text": "..." },
  "2": { "title": "Gate 2 – ..." , "text": "..." }
}
````

**Validation**:

* if found <64 → write to `lore-research/research-outputs/BAD_LINES.md`:

  * `gate: 37 | reason: not found in LC, check I Ching`

---

### 3. Line Extractor (`03-split-lines-per-gate.py`)

**Purpose**: get 6 lines from each gate.

**Input**:

* `lore-research/research-outputs/line-companion-gates.json`

**Logic**:

* detect variants: `Line 1`, `1st line`, `Line 1 –`, `Line 1:` (OCR is messy)
* capture until next line OR next gate
* if we get <6 lines, we still write what we have but **flag it**

**Output**:

```json
{
  "1": {
    "1": { "title": "Creation is independent of will", "text": "..." },
    "2": { ... }
  },
  "2": { ... }
}
```

**Errors** → `BAD_LINES.md`:

* missing line
* duplicate line
* line body empty

---

### 3b. Hexagram Cross-Check (`03b-xcheck-with-hexagrams.py`)

**Purpose**: stop semantic drift.

**Input**:

* line file: `lore-research/research-outputs/line-companion-gate-lines.json`
* hexagrams: `s3-data/hexagrams/01.json` … `64.json`

**Logic**:

* map HD gate → hexagram: `gate N → hexagram N` (for this project)
* for each line:

  * compare LC text to `hexagrams/N.json.lines[i].translations[*].text`
  * if LC is clearly talking about a different actor/stance than hexagram → mark:

    ```json
    "hexagram_conflict": true,
    "hexagram_source": "s3-data/hexagrams/01.json"
    ```
  * if LC is shorter but aligned → mark:

    ```json
    "hexagram_match": true
    ```

**Output**:

* `lore-research/research-outputs/line-companion-gate-lines-xchecked.json`
* If `hexagram_conflict == true`, also writes `lc_source_file` and `lc_source_offset` to help reopen the original

**Rule**:

* if `hexagram_conflict == true` → Stage 4 must prefer the hexagram sentence.

---

### 4. Quote Selector (`04-extract-quotes.py`)

**Purpose**: get sub-25-word quote for every line.

**Input**:

* `lore-research/research-outputs/line-companion-gate-lines-xchecked.json`

**Logic**:

1. if `hexagram_conflict == true` → use hexagram line text as source
2. else → use LC line text
3. extract first sentence ≤25 words
4. if none ≤25 → truncate to 25 and add `...`
5. detect and **store** `exaltation` / `detriment` patterns if present (each ≤25 words)
6. store citation metadata

**Output**:

```json
{
  "1": {
    "1": {
      "quote": "The dragon lies hid in the deep; it is not the time for active doing.",
      "word_count": 20,
      "exaltation": "<≤25 words or null>",
      "detriment": "<≤25 words or null>",
      "source": "I Ching (Legge 1899)",
      "hexagram_source": "s3-data/hexagrams/01.json",
      "priority": "hexagram",
      "citation": {
        "author": "Ra Uru Hu",
        "work": "Line Companion"
      }
    }
  }
}
```

**Important**:

* quotes MUST stay ≤25 words
* if no good quote → write stub:

  ```json
  {
    "quote": "",
    "status": "needs_manual",
    "reason": "OCR_fragment"
  }
  ```

  and list it in `BAD_LINES.md`

---

### 5. Quote Merger (`06-merge-quotes-into-gates.py`)

**Purpose**: update gate files **without clobbering** hand-edited data.

**Input**:

* `lore-research/research-outputs/line-companion-quotes.json`
* `s3-data/gates/*.json`

**Processing**:

* read gate file
* for each line 1-6:

  * if quote exists and `status != needs_manual`:

    * writes to `classical` block with: `hd_quote`, `exaltation`, `detriment`, and full `citation` (author, work, source_file, page_or_locator, extraction_method):

      ```json
      "classical": {
        "hd_quote": "...",
        "exaltation": "...",
        "detriment": "...",
        "citation": {
          "author": "Ra Uru Hu",
          "work": "Line Companion",
          "source_file": "line-companion-normalized.txt",
          "page_or_locator": "gate 1, line 1",
          "extraction_method": "normalized"
        },
        "word_count": 23
      }
      ```

      (if `priority == "hexagram"`, flip the source)
  * **do not touch** other parts of the line (behavioral_axis, star_system_alignment, etc.)
* **write to**: `s3-data/gates/_candidate/<gate>.json`

  * never overwrite the live file directly
  * human/agent promotes `_candidate` → live after review

**Why**: you already have a lot of human/Claude work in `s3-data/gates/`. We don’t nuke that.

---

### 6. Validator (`07-validate-gates.py`)

**Purpose**: final guardrail.

**Checks**:

1. 64 gates present
2. 6 lines per gate
3. every line has either

   * a <=25-word quote **OR**
   * a `needs_manual` entry
4. every quote has `source`
5. every line links to **hexagram N** (no off-by-one)
6. optional: warn if a quote came **only** from Line Companion and no hexagram was available

**Output**:

```json
{
  "total_gates": 64,
  "total_lines": 384,
  "valid_lines": 372,
  "needs_manual": [
    "14.3",
    "27.5"
  ],
  "notes": [
    "27.5: LC OCR fragment, check PDF/EPUB"
  ]
}
```

Also write/update:

* `lore-research/research-outputs/BAD_LINES.md`

---

## Data Models

(keep yours, just add two fields)

**line-companion-quotes.json**:

```json
{
  "<gate_number>": {
    "<line_number>": {
      "quote": "<extracted_or_hexagram_quote>",
      "word_count": 23,
      "exaltation": "<≤25 words or null>",
      "detriment": "<≤25 words or null>",
      "source": "Ra Uru Hu, Line Companion",
      "hexagram_source": "s3-data/hexagrams/01.json",
      "priority": "line_companion | hexagram",
      "status": "ok | needs_manual",
      "citation": {
        "author": "Ra Uru Hu",
        "work": "Line Companion"
      }
    }
  }
}
```

---

## Error Handling

* **Missing gate/line** → log + BAD_LINES.md
* **OCR garbage** → mark `needs_manual`
* **Hexagram mismatch** → prefer hexagram, flag it
* **Merge failure** → keep original gate file untouched

---

## Testing Strategy

* unit tests for:

  * regex for gates
  * regex for lines (with weird “1st line” / “Line l” OCR)
  * quote truncation
  * hexagram preference
* integration: run whole pipeline on 2–3 gates (1, 27, 36)
* manual: open PDF/EPUB and spot-check 10 gates

**Acceptance**: ≥95% of 10-gate sample matches source verbatim (or source-first 25 words).

---

## Deployment / Runbook

```bash
python 01-normalize-line-companion.py
python 02-split-gates.py
python 03-split-lines-per-gate.py
python 03b-xcheck-with-hexagrams.py
python 04-extract-quotes.py
# (05 reserved for future use)
python 06-merge-quotes-into-gates.py
python 07-validate-gates.py
```

Outputs to:

* `lore-research/research-outputs/...` (intermediate)
* `s3-data/gates/_candidate/...` (final)
* `lore-research/research-outputs/BAD_LINES.md` (review)

---

---

## Star System Correlation (Phase 2)

**Purpose**: Enable any S³ data object to be scored against all 8 v4.2 star-system baselines.

**Input**:
- Any object from the 6 core collections (gates, hexagrams, channels, centers, circuits, line_archetypes)
- 8 star-system baseline files from `lore-research/research-outputs/star-systems/v4.2/`
- Association data from `s3-data/associations/gate-line-to-star.v2.json`

**Logic**:
- For each gate.line, generate correlation record with scores for all 8 systems
- Include `source_alignment` block linking hexagram → HD gate → star score
- Use existing association mappings where available
- Fall back to `s3-data/pipeline_rules/derivation.v1.json` if needed

**Output**: Correlation records with star_scores for Andromeda, Arcturus, Draco, Lyra, Orion (Dark), Orion (Light), Pleiades, Sirius

**Note**: This is deferred to Phase 2 as it requires the gate.line quotes to be finalized first.

---

## Channels, Centers, Circuits Integration (Phase 2)

**Purpose**: Extend Ra quote integration beyond gates to other S³ collections.

**Channels** (`s3-data/channels/*.json`):
- Extract gate-level Ra phrases from Line Companion
- Replace long placeholder text with concise Ra quotes
- For abstracted channels (e.g., 1-8), store multiple Ra snippets in array
- Maintain ≤25 word limit per snippet

**Centers** (`s3-data/centers/*.json`):
- Best-effort extraction only
- If Ra never spoke directly to a center, set `ra_quote: null` with `citation_status: "not_applicable"`
- Update `meta.provenance` to document Ra quote presence

**Circuits** (`s3-data/circuits/*.json`):
- Store 1-3 short Ra fragments to justify circuit inclusion
- If missing, mark as `citation_status: "provisional"`
- Update `meta.provenance` consistently

**Note**: This is deferred to Phase 2 to focus MVP on gates and hexagrams first. This defers FR-DI-4 from the requirements.md (channels/centers/circuits) to Phase 2.

---

## Future Enhancements

* EPUB-first extraction (cleaner)
* auto-page-number from `*_page_numbers.json`
* optional: CLI flag `--promote` to move `_candidate` → live after clean validation
* Wilhelm/Baynes translation integration as secondary I Ching source